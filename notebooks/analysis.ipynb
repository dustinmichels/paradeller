{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from paradeller.samples import sample1, sample2, sample3\n",
    "from paradeller.analysis import tokenize\n",
    "from paradeller.helper import load_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get samples into standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COUNTER = 0\n",
    "\n",
    "def datafy_poem(text, name):\n",
    "    global ID_COUNTER\n",
    "    # get lines, remove duplicates\n",
    "    lines = [\n",
    "        ' '.join(tokenize(x)) for x in text.split(\"\\n\")\n",
    "        if x != ''\n",
    "    ]\n",
    "    # convert to dict\n",
    "    data = []\n",
    "    for i, line in enumerate(lines):\n",
    "        data.append(dict(\n",
    "            id=ID_COUNTER,\n",
    "            text=line,\n",
    "            poem=name,\n",
    "            line=i\n",
    "        ))\n",
    "        ID_COUNTER += 1\n",
    "    return data\n",
    "\n",
    "data1 = datafy_poem(sample1, \"sample1\")\n",
    "data2 = datafy_poem(sample2, \"sample2\")\n",
    "data3 = datafy_poem(sample3, \"sample3\")\n",
    "data = data1 + data2 + data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>poem</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sample1</td>\n",
       "      <td>meet me on the darkest sea of dead stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sample1</td>\n",
       "      <td>meet me on the darkest sea of dead stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sample1</td>\n",
       "      <td>when the waves burn my skin iâ€™ll remember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sample1</td>\n",
       "      <td>when the waves burn my skin iâ€™ll remember</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sample1</td>\n",
       "      <td>iâ€™ll remember the burn on the darkest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>sample1</td>\n",
       "      <td>sea of dead waves when my skin meet me stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line     poem                                          text\n",
       "id                                                             \n",
       "0      0  sample1      meet me on the darkest sea of dead stars\n",
       "1      1  sample1      meet me on the darkest sea of dead stars\n",
       "2      2  sample1     when the waves burn my skin iâ€™ll remember\n",
       "3      3  sample1     when the waves burn my skin iâ€™ll remember\n",
       "4      4  sample1         iâ€™ll remember the burn on the darkest\n",
       "5      5  sample1  sea of dead waves when my skin meet me stars"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data).set_index('id')\n",
    "\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_archive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Adj. Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paradeller.analysis import (\n",
    "    make_adj_list_by_word, make_adj_list_by_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list_words = make_adj_list_by_word(data)\n",
    "\n",
    "# print(adj_list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list_ids = make_adj_list_by_id(data)\n",
    "\n",
    "# print(adj_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(i):\n",
    "    return next(x for x in data if x['id'] == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID1 = 0\n",
    "# ID2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID1 = 1144358142387662851\n",
    "# ID2 = 1144358142219837440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_tweet(ID1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_tweet(ID2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paradeller.analysis import (\n",
    "    get_master_word_set,\n",
    "    get_potential_tweets,\n",
    "    filter_potential_tweets,\n",
    "    find_valid_matches,\n",
    "    find_maches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(adj_list_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45832"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_ids = [\n",
    "    random.choice(ids)\n",
    "    for _ in range(500)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124750"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos = list(combinations(some_ids, 2))\n",
    "len(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124750/124750 [28:52<00:00, 72.00it/s] \n"
     ]
    }
   ],
   "source": [
    "all_valid = {}\n",
    "\n",
    "for c in tqdm(combos):\n",
    "    valid = find_maches(c[0], c[1], adj_list_ids, adj_list_words)\n",
    "    if (valid):\n",
    "        all_valid[c] = valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_exact_match(start_pair, found_pair):\n",
    "    t1, t2 = start_pair\n",
    "    ta, tb = found_pair\n",
    "    return not (\n",
    "        (adj_list_ids[ta] == adj_list_ids[t1]) or\n",
    "        (adj_list_ids[ta] == adj_list_ids[t2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(start_pair, found_pair):\n",
    "    t1, t2 = start_pair\n",
    "    ta, tb = found_pair\n",
    "    return (\n",
    "        (adj_list_ids[ta] == adj_list_ids[t1]) or\n",
    "        (adj_list_ids[ta] == adj_list_ids[t2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_lines(t1, t2, exact_matches, adj_list_ids):\n",
    "    \n",
    "    words1 = adj_list_ids[t1]\n",
    "    words2 = adj_list_ids[t2]\n",
    "    \n",
    "    for pair in exact_matches:\n",
    "        a, b = pair\n",
    "        if (words1 == adj_list_ids[a]) and (words2 == adj_list_ids[b]):\n",
    "            return [t1, a, t2, b]\n",
    "        if (words1 == adj_list_ids[b]) and (words2 == adj_list_ids[a]):\n",
    "            return [t1, b, t2, b]\n",
    "    \n",
    "    return [t1, t1, t2, t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@DiamondMangum        Iâ€™m tired ðŸ˜“ \n",
      "@DiamondMangum        Iâ€™m tired ðŸ˜“ \n",
      "@She_Daaeee           Iâ€™m so hungry ðŸ˜© \n",
      "@She_Daaeee           Iâ€™m so hungry ðŸ˜© \n",
      "@Miyakelashaee_       Iâ€™m hungry . \n",
      "@shanice_thusi        Iâ€™m so tired ðŸ˜“ \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@DiamondMangum        Iâ€™m tired ðŸ˜“ \n",
      "@DiamondMangum        Iâ€™m tired ðŸ˜“ \n",
      "@RJIVE                MONI IS SO CUTE \n",
      "@RJIVE                MONI IS SO CUTE \n",
      "@shanice_thusi        Iâ€™m so tired ðŸ˜“ \n",
      "@_lychiii_            moni is so cute ðŸ¥ºðŸ¥ºðŸ¥ºðŸ¥º \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@DiamondMangum        Iâ€™m tired ðŸ˜“ \n",
      "@DiamondMangum        Iâ€™m tired ðŸ˜“ \n",
      "@MostHATED_Noump      Iâ€™m so fucking irritated \n",
      "@MostHATED_Noump      Iâ€™m so fucking irritated \n",
      "@JossiGainza          So fucking tired \n",
      "@tayyysiaaaaa         Iâ€™m so irritated \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@lysaaaab             WHAT IT DO BABYYYYYYYY \n",
      "@lysaaaab             WHAT IT DO BABYYYYYYYY \n",
      "@mikestooksbot        . That was \n",
      "@mikestooksbot        . That was \n",
      "@elianna_sanchez      That was it? \n",
      "@nayytitts            What it do babyyyyyyyy \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@DhaniNextDoor        DLO TO THE WARRIORS??? \n",
      "@DhaniNextDoor        DLO TO THE WARRIORS??? \n",
      "@HerciMerci           The Warriors donâ€™t rebuild. They reload. \n",
      "@HerciMerci           The Warriors donâ€™t rebuild. They reload. \n",
      "@mannvirsingh_        Warriors donâ€™t rebuild ... they reload ðŸ¤£ðŸ‘€ \n",
      "@_kendadon            Dlo to the warriors \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@GeorgeLambert15      This NBA Free Agency is WILD!!! ðŸ¤¯ðŸ¤¯ \n",
      "@GeorgeLambert15      This NBA Free Agency is WILD!!! ðŸ¤¯ðŸ¤¯ \n",
      "@mikestooksbot        . That was \n",
      "@mikestooksbot        . That was \n",
      "@annakaye__           that was wild \n",
      "@AdenWare             This NBA free agency is wild \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@She_Daaeee           Iâ€™m so hungry ðŸ˜© \n",
      "@Mrs_Walls15          Iâ€™m so hungry ðŸ˜© \n",
      "@RJIVE                MONI IS SO CUTE \n",
      "@_lychiii_            moni is so cute ðŸ¥ºðŸ¥ºðŸ¥ºðŸ¥º \n",
      "@lordinaryxo          Iâ€™m hungry ðŸ˜­ \n",
      "@_lychiii_            moni is so cute ðŸ¥ºðŸ¥ºðŸ¥ºðŸ¥º \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@AuntyAdj             I love Maura \n",
      "@Mahsox               I love maura ðŸ˜‚ðŸ˜­ \n",
      "@Mela_Vale            I can't sleep ðŸ˜£ \n",
      "@Mahsox               I love maura ðŸ˜‚ðŸ˜­ \n",
      "@daaanuuuhhh          can't sleep :((( \n",
      "@Mahsox               I love maura ðŸ˜‚ðŸ˜­ \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@Younqtay_3           Dlo To the warriors ðŸ¥¶ \n",
      "@Younqtay_3           Dlo To the warriors ðŸ¥¶ \n",
      "@HerciMerci           The Warriors donâ€™t rebuild. They reload. \n",
      "@HerciMerci           The Warriors donâ€™t rebuild. They reload. \n",
      "@mannvirsingh_        Warriors donâ€™t rebuild ... they reload ðŸ¤£ðŸ‘€ \n",
      "@DhaniNextDoor        DLO TO THE WARRIORS??? \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "@llqxzw               I donâ€™t feel good...... \n",
      "@jsnwaterfallz        I donâ€™t feel good \n",
      "@Mela_Vale            I can't sleep ðŸ˜£ \n",
      "@jsnwaterfallz        I donâ€™t feel good \n",
      "@CabilloLaika         Can't sleep  :(((( \n",
      "@jsnwaterfallz        I donâ€™t feel good \n"
     ]
    }
   ],
   "source": [
    "for pair, matches in all_valid.items():\n",
    "    t1, t2 = pair\n",
    "    \n",
    "    words1 = adj_list_ids[t1]\n",
    "    words2 = adj_list_ids[t2]\n",
    "    \n",
    "    exact_matches = [m for m in matches if exact_match(pair, m)]\n",
    "    non_exact_matches = list(set(matches) - set(exact_matches))\n",
    "    \n",
    "    if non_exact_matches:\n",
    "        # look for reframing of first lines\n",
    "        stanza = find_start_lines(t1, t2, exact_matches, adj_list_ids)\n",
    "            \n",
    "        stanza.extend([\n",
    "            non_exact_matches[0][0],\n",
    "            non_exact_matches[0][1]\n",
    "        ])\n",
    "        \n",
    "        print(\"~\"*50)\n",
    "        for t in stanza:\n",
    "            tweet = get_tweet(t)\n",
    "            print(f\"@{tweet['author']:20} {tweet['text']} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am i so hard to love ?\n",
      "Am drunk ðŸ˜¤\n",
      "i am dRunk\n",
      "Am i so hard to love?\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Am i so hard to love ?\n",
      "God is good ðŸ¤žðŸ¾\n",
      "God is so good\n",
      "Am i so hard to love?\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "I keep thinking today is Saturday\n",
      "Am drunk ðŸ˜¤\n",
      "i am dRunk\n",
      "I keep thinking today is Saturday ðŸ˜‚ðŸ˜­\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Acid Rap is on Spotify now. ðŸ™ŒðŸ»ðŸ™ŒðŸ»ðŸ™ŒðŸ»\n",
      "itâ€™s above me!\n",
      "itâ€™s above me now.\n",
      "Acid Rap is on Spotify ðŸ™ŒðŸ½ðŸ™ŒðŸ½ðŸ™ŒðŸ½\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Acid Rap is on Spotify now. ðŸ™ŒðŸ»ðŸ™ŒðŸ»ðŸ™ŒðŸ»\n",
      "itâ€™s above me!\n",
      "Itâ€™s above me now ðŸ¤·ðŸ½â€â™€ï¸\n",
      "Acid Rap is on Spotify ðŸ™ŒðŸ½ðŸ™ŒðŸ½ðŸ™ŒðŸ½\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "God is good ðŸ¤žðŸ¾\n",
      "LETS GO USA âš½ï¸ðŸ‡ºðŸ‡¸\n",
      "lets go USA\n",
      "God is good ðŸ™ðŸ¼â¤ï¸\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "God is good ðŸ¤žðŸ¾\n",
      "I am so hungry.\n",
      "God is so good\n",
      "i am hungry\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "for pair, matches in all_valid.items():\n",
    "    t1, t2 = pair\n",
    "    \n",
    "    words1 = adj_list_ids[t1]\n",
    "    words2 = adj_list_ids[t2]\n",
    "    \n",
    "    for m in matches:\n",
    "        a, b = m\n",
    "        if (adj_list_ids[a] != words1) and (adj_list_ids[a] != words2):\n",
    "            print(get_tweet(t1)['text'])\n",
    "            print(get_tweet(t2)['text'])\n",
    "            print(get_tweet(a)['text'])\n",
    "            print(get_tweet(b)['text'])\n",
    "            print(\"~\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = find_maches(t1, t2, adj_list_ids, adj_list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in matches:\n",
    "    a, b = m\n",
    "    if not ((adj_list_ids[a] == words1) or (adj_list_ids[a] == words2)):\n",
    "        print(get_tweet(a)['text'])\n",
    "        print(get_tweet(b)['text'])\n",
    "        print(\"~\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1144708038831550468, 1145534442682945537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1144708038831550468,\n",
       " 'text': 'Ovie ðŸ˜ðŸ˜˜ðŸ˜˜ðŸ˜˜ #LoveIsland',\n",
       " 'author': 'ehidodo',\n",
       " 'time': '2019-06-28 20:43:58'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweet(1144708038831550468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1145534442682945537,\n",
       " 'text': 'Hello July ðŸ‘‹ðŸ½ðŸ–¤.',\n",
       " 'author': 'AObaid23',\n",
       " 'time': '2019-07-01 03:27:48'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweet(1145534442682945537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1145542253177425920, 1144708101590962176)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1145542253177425920, 1144708101590962176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1145542253177425920,\n",
       " 'text': 'Hello July ðŸ’™',\n",
       " 'author': 'ulll97',\n",
       " 'time': '2019-07-01 03:58:50'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweet(1145542253177425920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1144708101590962176,\n",
       " 'text': 'Ovie ðŸ˜° #loveisland',\n",
       " 'author': 'GeorgiaNunnx',\n",
       " 'time': '2019-06-28 20:44:13'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweet(1144708101590962176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_word_set = get_master_word_set(ID1, ID2, adj_list_ids)\n",
    "# master_word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_ids = get_potential_tweets(ID1, ID2, adj_list_words, adj_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_ids = filter_potential_tweets(\n",
    "    pot_ids, adj_list_ids, master_word_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pot_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1144677537576079362]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1144677537576079362,\n",
       " 'text': 'I hate I hate I hate',\n",
       " 'author': 'valeria_not',\n",
       " 'time': '2019-06-28 18:42:46'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweet(1144677537576079362)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = find_valid_matches(pot_ids, adj_list_ids, master_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count # times other lines share a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meet', 'me', 'on', 'the', 'darkest', 'sea', 'of', 'dead', 'stars']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tokens for id\n",
    "i = 0\n",
    "item = next(x for x in data if x['id'] == i)\n",
    "tokens = tokenize(item['text'])\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 9), (5, 6), (18, 6), (4, 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "for word in tokens:\n",
    "    line_ids = [\n",
    "        x for x in db[word]\n",
    "        if x != item['id']\n",
    "    ]\n",
    "    c.update(line_ids)\n",
    "    \n",
    "c.most_common(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 18, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [x[0] for x in c.most_common(4)]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>poem</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sample1</td>\n",
       "      <td>meet me on the darkest sea of dead stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>sample1</td>\n",
       "      <td>sea of dead waves when my skin meet me stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>sample1</td>\n",
       "      <td>on the darkest sea of dead abstraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sample1</td>\n",
       "      <td>iâ€™ll remember the burn on the darkest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    line     poem                                          text\n",
       "id                                                             \n",
       "1      1  sample1      meet me on the darkest sea of dead stars\n",
       "5      5  sample1  sea of dead waves when my skin meet me stars\n",
       "18    18  sample1        on the darkest sea of dead abstraction\n",
       "4      4  sample1         iâ€™ll remember the burn on the darkest"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53,898\n"
     ]
    }
   ],
   "source": [
    "a = load_archive()\n",
    "print(f\"{len(a):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53898/53898 [05:42<00:00, 157.29it/s]  \n"
     ]
    }
   ],
   "source": [
    "my_data = load_all(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,234,158\n"
     ]
    }
   ],
   "source": [
    "L = len(my_data)\n",
    "print(f\"{L:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.pickle', \"wb\") as file:\n",
    "    pickle.dump(my_data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
