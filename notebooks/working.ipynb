{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import json\n",
    "import tweepy\n",
    "\n",
    "from paradeller.keys import (\n",
    "    consumer_key, consumer_secret, access_token, accss_token_secret\n",
    ")\n",
    "\n",
    "from paradeller.stopwords import stopwords\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, accss_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good(t):\n",
    "    # low word count\n",
    "    tweet_len = len(t.split())\n",
    "    if (tweet_len < 3) or (tweet_len >= 10):\n",
    "        return False\n",
    "    \n",
    "    # no blacklistd works / symbols\n",
    "    for x in [\"@\", \"\\n\"]:\n",
    "        if x in t:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_status(status):\n",
    "    print(status.text)\n",
    "    print(f\"-- @{status.author.screen_name}\\n\")\n",
    "    print(status.id)\n",
    "    print(\"~\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets():\n",
    "    query = \"-filter:retweets -filter:links -filter:media\"\n",
    "    tweets = api.search(\n",
    "        q=query, lang='en', count=100, include_entities=False\n",
    "    )\n",
    "    return [t for t in tweets if is_good(t.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new Boris is lit\n",
      "-- @StudentOfEth\n",
      "\n",
      "1144356141872271360\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "I been sleep! I was tired asf\n",
      "-- @x_PinkNPearls\n",
      "\n",
      "1144356141868232713\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "sometimes I wish I had hoes\n",
      "-- @fauxlavie\n",
      "\n",
      "1144356141843066880\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Lets go torrejon\n",
      "-- @OmFetty\n",
      "\n",
      "1144356141817913344\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ALL OF THEM\n",
      "-- @stankrhodes\n",
      "\n",
      "1144356141713018880\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "these ain‚Äôt hickeys baby you know my chains fake\n",
      "-- @SophieA24683\n",
      "\n",
      "1144356141671100431\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Sometimes you just have to take the L\n",
      "-- @CFeli19\n",
      "\n",
      "1144356141549465614\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Creaturos - Last summers' #1 Hit Single\n",
      "-- @WZBC_Live\n",
      "\n",
      "1144356141503266816\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Rant over! I'm just angry üò°\n",
      "-- @IllestDJCarpel\n",
      "\n",
      "1144356141503143936\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Life on the line I‚Äôm taking a risk üôáüèæ‚Äç‚ôÇÔ∏è\n",
      "-- @_CurrencyTowers\n",
      "\n",
      "1144356141385695232\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Who else thinks Sherif looks like Stormzy??? #loveisland\n",
      "-- @GabzeeG\n",
      "\n",
      "1144356141373087744\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Riding to school on Goutengou now.\n",
      "-- @R_Ichiro_Tanaka\n",
      "\n",
      "1144356141222092800\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The Grand Canyon was pretty majestic\n",
      "-- @xoxocameragrl\n",
      "\n",
      "1144356141192929280\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "üò§ I only fw the chicken bacon ranch. üòõüòõ\n",
      "-- @twistedfate4me_\n",
      "\n",
      "1144356141092130816\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "was that jourdan in the blue or black\n",
      "-- @raidazyasmin\n",
      "\n",
      "1144356140974845953\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Lord lets win this.\n",
      "-- @kriskirimi\n",
      "\n",
      "1144356140928708619\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Don‚Äôt spend no bread ona thotty\n",
      "-- @Uptownshizzy\n",
      "\n",
      "1144356140857405451\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "res = get_tweets()\n",
    "\n",
    "for status in res:\n",
    "    display_status(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paradeller.helper import load_archive, update_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_status(status):\n",
    "    return dict(\n",
    "        id=status.id,\n",
    "        text=status.text,\n",
    "        author=status.author.screen_name,\n",
    "        time=status.created_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive = load_archive()\n",
    "len(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 167/1000 [01:45<08:37,  1.61it/s]Rate limit reached. Sleeping for: 119\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 347/1000 [05:48<07:33,  1.44it/s]  Rate limit reached. Sleeping for: 781\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 527/1000 [20:42<04:52,  1.62it/s]    Rate limit reached. Sleeping for: 791\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 707/1000 [35:53<02:54,  1.68it/s]    Rate limit reached. Sleeping for: 785\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 887/1000 [50:55<01:27,  1.29it/s]    Rate limit reached. Sleeping for: 788\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [1:05:25<00:00,  1.74it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10206"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "for i in trange(n):    \n",
    "    # get tweets\n",
    "    statuses = get_tweets()\n",
    "    \n",
    "    # get into save format\n",
    "    tweets = [save_status(s) for s in statuses]\n",
    "\n",
    "    # add to archive list\n",
    "    archive.extend(tweets)\n",
    "\n",
    "    \n",
    "# save to file\n",
    "update_archive(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10206"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive = load_archive()\n",
    "len(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_status(status):\n",
    "    return dict(\n",
    "        id=status.id,\n",
    "        text=status.text,\n",
    "        author=status.author.screen_name,\n",
    "        time=status.created_at\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_status_from_id(id_):\n",
    "    status = api.get_status(id_)\n",
    "    return save_status(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\n",
    "    1144127521929224197,\n",
    "    1144135638721036288,\n",
    "    1144135638733557760,\n",
    "    1144137985971183616,\n",
    "    1144144954219999232,\n",
    "    1144146074321317888,\n",
    "    1144313057377546240,\n",
    "    1144313057444847621\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = []\n",
    "for id_ in ids:\n",
    "    try:\n",
    "        s = save_status_from_id(id_)\n",
    "        saved.append(s)\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e)\n",
    "        print(\">> \", id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1144127521929224197,\n",
       "  'text': 'Sitting in lingerie drinking wine ima wife for sure üò≠',\n",
       "  'author': '__mxvii',\n",
       "  'time': datetime.datetime(2019, 6, 27, 6, 17, 12)},\n",
       " {'id': 1144135638721036288,\n",
       "  'text': 'time will be frozen for us',\n",
       "  'author': 'mariuuhhhh',\n",
       "  'time': datetime.datetime(2019, 6, 27, 6, 49, 27)},\n",
       " {'id': 1144135638733557760,\n",
       "  'text': 'Is it me or is it a break up season?',\n",
       "  'author': 'Linnneyyy',\n",
       "  'time': datetime.datetime(2019, 6, 27, 6, 49, 27)},\n",
       " {'id': 1144137985971183616,\n",
       "  'text': 'ive been gettin horny at the most inconvenient times lately wtf ü•¥üò´',\n",
       "  'author': 'SoCvsh',\n",
       "  'time': datetime.datetime(2019, 6, 27, 6, 58, 47)},\n",
       " {'id': 1144144954219999232,\n",
       "  'text': 'Fuck work experience üñïüèæüñïüèæ',\n",
       "  'author': 'juggz_19',\n",
       "  'time': datetime.datetime(2019, 6, 27, 7, 26, 28)},\n",
       " {'id': 1144146074321317888,\n",
       "  'text': 'All you can do is watch.',\n",
       "  'author': 'ayeroven',\n",
       "  'time': datetime.datetime(2019, 6, 27, 7, 30, 55)},\n",
       " {'id': 1144313057377546240,\n",
       "  'text': 'Piercing my belly üôá\\u200d‚ôÄÔ∏è',\n",
       "  'author': 'SuriouslyStace',\n",
       "  'time': datetime.datetime(2019, 6, 27, 18, 34, 27)},\n",
       " {'id': 1144313057444847621,\n",
       "  'text': 'did I mention i‚Äôm gay?',\n",
       "  'author': 'hoeslynn',\n",
       "  'time': datetime.datetime(2019, 6, 27, 18, 34, 27)}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import string\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tweet):\n",
    "    tweet = ' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    words = tweet.split()\n",
    "    return [\n",
    "        w.lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
    "        for w in words\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sitting',\n",
       " 'in',\n",
       " 'lingerie',\n",
       " 'drinking',\n",
       " 'wine',\n",
       " 'ima',\n",
       " 'wife',\n",
       " 'for',\n",
       " 'sure',\n",
       " 'üò≠']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(saved[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick some tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1144127521929224197,\n",
       " 'text': 'Sitting in lingerie drinking wine ima wife for sure üò≠',\n",
       " 'author': '__mxvii',\n",
       " 'time': datetime.datetime(2019, 6, 27, 6, 17, 12)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = saved[0]\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1144313057444847621,\n",
       " 'text': 'did I mention i‚Äôm gay?',\n",
       " 'author': 'hoeslynn',\n",
       " 'time': datetime.datetime(2019, 6, 27, 18, 34, 27)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = saved[7]\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set(tokenize(s1['text']) + tokenize(s2['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'did',\n",
       " 'drinking',\n",
       " 'for',\n",
       " 'gay',\n",
       " 'i',\n",
       " 'ima',\n",
       " 'in',\n",
       " 'i‚Äôm',\n",
       " 'lingerie',\n",
       " 'mention',\n",
       " 'sitting',\n",
       " 'sure',\n",
       " 'wife',\n",
       " 'wine',\n",
       " 'üò≠'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'did',\n",
       " 'drinking',\n",
       " 'gay',\n",
       " 'i',\n",
       " 'ima',\n",
       " 'i‚Äôm',\n",
       " 'lingerie',\n",
       " 'mention',\n",
       " 'sitting',\n",
       " 'sure',\n",
       " 'wife',\n",
       " 'wine',\n",
       " 'üò≠'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_words = word_set - set(stopwords)\n",
    "search_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'did',\n",
       " 'drinking',\n",
       " 'gay',\n",
       " 'i',\n",
       " 'ima',\n",
       " 'i‚Äôm',\n",
       " 'lingerie',\n",
       " 'mention',\n",
       " 'sitting',\n",
       " 'sure',\n",
       " 'wife',\n",
       " 'wine',\n",
       " 'üò≠'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'did',\n",
       " 'drinking',\n",
       " 'gay',\n",
       " 'i',\n",
       " 'ima',\n",
       " 'i‚Äôm',\n",
       " 'lingerie',\n",
       " 'mention',\n",
       " 'sitting',\n",
       " 'sure',\n",
       " 'wife',\n",
       " 'wine',\n",
       " 'üò≠'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sure OR did OR üò≠ OR mention OR sitting OR wine OR i OR wife OR lingerie OR ima OR drinking OR gay OR i‚Äôm -filter:retweets -filter:links -filter:media\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    ' OR '.join(search_words) + \n",
    "    \" -filter:retweets -filter:links -filter:media\"\n",
    ")\n",
    "print(query)\n",
    "\n",
    "def get_search_tweets():\n",
    "    tweets = api.search(\n",
    "        q=query, lang='en', count=1000, include_entities=False\n",
    "    )\n",
    "    return [t for t in tweets if is_good(t.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_match(tweet, word_set):\n",
    "    \"\"\"\n",
    "    If all words in tweet are in the word set,\n",
    "    it is a potential match\n",
    "    \"\"\"\n",
    "    words = tokenize(tweet)\n",
    "    return set(words) <= word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 68/1000 [00:42<08:34,  1.81it/s]Rate limit reached. Sleeping for: 347\n",
      " 25%|‚ñà‚ñà‚ñç       | 248/1000 [08:20<07:22,  1.70it/s]   Rate limit reached. Sleeping for: 793\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 428/1000 [23:29<05:28,  1.74it/s]    Rate limit reached. Sleeping for: 790\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 608/1000 [38:37<04:04,  1.60it/s]    Rate limit reached. Sleeping for: 787\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 788/1000 [53:50<02:18,  1.53it/s]    Rate limit reached. Sleeping for: 779\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [1:09:07<00:00,  1.36it/s]   \n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "\n",
    "matches = []\n",
    "\n",
    "for i in trange(iterations):\n",
    "    res = get_search_tweets()\n",
    "    for status in res:\n",
    "        if potential_match(status.text, word_set):\n",
    "            print(\"yeah!!\")\n",
    "            display_status(status)\n",
    "            mactches.append(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
